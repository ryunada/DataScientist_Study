{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc4a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률적 경사 하강법(SGD; Stochastic Gradient Descent)\n",
    "class SGD:\n",
    "    def __init__(self, lr = 0.01):\n",
    "        self.lr = lr\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]\n",
    "            \n",
    "# python 소스 코드\n",
    "weight[i] += - learning_rate * gradient\n",
    "\n",
    "# Keras 소스 코드\n",
    "kearas.optimizers.SGD(lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde79145",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SGD 모멘텀(Momentum)\n",
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():                                \n",
    "                self.v[key] = np.zeros_like(val)\n",
    "                \n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key] \n",
    "            params[key] += self.v[key]\n",
    "            \n",
    "# python 소스 코드\n",
    "v = m * v - learning_rate * gradient\n",
    "weight[i] += v\n",
    "\n",
    "# Tensorflow 소스 코드\n",
    "optimize = tf.train.MomentumOptimizer(learning_rate = 0.01, momentum = 0.9).minimize(loss)\n",
    "\n",
    "# Keras 소스 코드\n",
    "keras.optimizers.SGD(lr = 0.1, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesterov Accelrated Gradient(NAG, 네스테로프 모멘텀)\n",
    "\n",
    "# python 소스 코드\n",
    "v = m * v - learning_rate * gradient(weight[i-1] + m * v)\n",
    "weight[i] += v\n",
    "\n",
    "# Tensorflow 소스 코드\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate = 0.01, momentum = 0.9, use_nesterov = True).minimize(loss)\n",
    "\n",
    "# Keras 소스 코드\n",
    "keras.optimizers.SGD(lr = 0.1, momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSProp\n",
    "\n",
    "# python 소스 코드\n",
    "g = gamma * g + (1 - gamma) * gradient ** 2\n",
    "weight[i] += - learning_rate * gradient / (np.sqrt(g) + e)\n",
    "\n",
    "# Tensorflow 소스 코드\n",
    "optimize = tf.train.RMSPropOptimizer(learning_rate = 0.01, decay = 0.9, momentum = 0.0, epsilon = le - 1).minimizer(cost)\n",
    "\n",
    "# Keras 소스 코드\n",
    "keras.optimizers.RMSprop(lr = 0.001, rho = 0.9, epsilon = None, decay = 0.0)\n",
    "# 하이퍼-파라미터 rho ==  𝛾(감마)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaGrad\n",
    "class AdaGrad:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "            \n",
    "        for key in params.keys():\n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n",
    "            \n",
    "# python 소스 코드\n",
    "g += gradient**2\n",
    "weight[i] += - learning_rate(gradient / (np.sqrt(g) + e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam\n",
    "\n",
    "# Tensorflow 소스 코드\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001, betal = 0.9, beta2 = 0.999, epsilon=1e-08).minimizer(loss)\n",
    "\n",
    "# Kearas 소스 코드\n",
    "keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec7b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeedde0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af80617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668c3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adcdaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
